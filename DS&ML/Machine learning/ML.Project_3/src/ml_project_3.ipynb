{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eae8942",
   "metadata": {},
   "source": [
    "## 1. Answer the questions from the introduction\n",
    "   1. What is leave-one-out? Provide limitations and strengths.\n",
    "   2. How do Grid Search, Randomized Grid Search, and Bayesian optimization work?\n",
    "   3. Explain classification of feature selection methods. Explain how Pearson and Chi2 work. Explain how Lasso works. Explain what permutation significance is. Become familiar with SHAP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecad81f",
   "metadata": {},
   "source": [
    "1. Leave-one-out (LOO) — это метод кросс-валидации, при котором для обучения модели поочередно используется все объекты набора данных, кроме одного, который в свою очередь используется для тестирования\n",
    "\n",
    "Плюсы:\n",
    "- Максимально использует данные для обучения\n",
    "- Практически несмещённая оценка модели\n",
    "- Особенно полезен при очень маленьких выборках\n",
    "\n",
    "Минусы:\n",
    "- Очень дорог по вычислениям (обучение N раз)\n",
    "- Результаты могут быть нестабильными из-за высокой вариативности\n",
    "- Возможен переобучение из-за обучения почти на всей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ad7fe",
   "metadata": {},
   "source": [
    "2.\n",
    "* Grid Search — перебирает все возможные комбинации заданных гиперпараметров в решётке (grid), обучая и оценивая модель на каждой. Хорош для малых размерностей, но дорог по времени.\n",
    "\n",
    "* Randomized Grid Search — случайно выбирает фиксированное число комбинаций из пространства гиперпараметров. Быстрее Grid Search, лучше для больших и сложных пространств, но не гарантирует полный перебор.\n",
    "\n",
    "* Bayesian Optimization — строит модель вероятностной зависимости функции качества от гиперпараметров и итеративно выбирает новые параметры для оценки с учетом предыдущих результатов. Более эффективен и экономит вычисления, особенно при дорогом обучении модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f926f8c3",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "Pearson — измеряет линейную корреляцию между признаком и целевой переменной, отбирает признаки с высокой корреляцией.\n",
    "\n",
    "Chi2 — проверяет независимость категориального признака от класса, выделяя значимые.\n",
    "\n",
    "Lasso — линейная регрессия с L1-регуляризацией, «обнуляет» коэффициенты неважных признаков, тем самым отбирая лучшие.\n",
    "\n",
    "Permutation significance — оценивает важность признака путем случайного перемешивания его значений и сравнения ухудшения качества модели.\n",
    "\n",
    "SHAP — метод объяснения моделей с помощью оценки вклада каждого признака в предсказание на основе теории кооперативных игр."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c8fdb",
   "metadata": {},
   "source": [
    "## 2. Introduction — do all the preprocessing from the previous lesson\n",
    "   1. Read all the data.\n",
    "   2. Preprocess the \"Interest Level\" feature.\n",
    "   3. Create features:  'Elevator', 'HardwoodFloors', 'CatsAllowed', 'DogsAllowed', 'Doorman', 'Dishwasher', 'NoFee', 'LaundryinBuilding', 'FitnessCenter', 'Pre-War', 'LaundryInUnit', 'RoofDeck', 'OutdoorSpace', 'DiningRoom', 'HighSpeedInternet', 'Balcony', 'SwimmingPool', 'LaundryInBuilding', 'NewConstruction', 'Terrace'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26a96a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, TimeSeriesSplit, train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import shap\n",
    "import optuna\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a9483f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>created</th>\n",
       "      <th>Elevator</th>\n",
       "      <th>HardwoodFloors</th>\n",
       "      <th>CatsAllowed</th>\n",
       "      <th>DogsAllowed</th>\n",
       "      <th>Doorman</th>\n",
       "      <th>Dishwasher</th>\n",
       "      <th>...</th>\n",
       "      <th>LaundryinUnit</th>\n",
       "      <th>RoofDeck</th>\n",
       "      <th>OutdoorSpace</th>\n",
       "      <th>DiningRoom</th>\n",
       "      <th>HighSpeedInternet</th>\n",
       "      <th>Balcony</th>\n",
       "      <th>SwimmingPool</th>\n",
       "      <th>LaundryInBuilding</th>\n",
       "      <th>NewConstruction</th>\n",
       "      <th>Terrace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-16 05:55:27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-01 05:44:33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-14 15:19:59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-28 03:50:23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124000</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-05 03:58:33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124002</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-02 02:25:31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124004</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-26 05:42:03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124008</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-19 02:47:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124009</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-20 05:34:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48343 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms interest_level              created  Elevator  \\\n",
       "4               1         1              1  2016-06-16 05:55:27         0   \n",
       "6               1         2              0  2016-06-01 05:44:33         1   \n",
       "9               1         2              1  2016-06-14 15:19:59         1   \n",
       "10              1         3              1  2016-06-24 07:54:24         0   \n",
       "15              1         0              0  2016-06-28 03:50:23         1   \n",
       "...           ...       ...            ...                  ...       ...   \n",
       "124000          1         3              0  2016-04-05 03:58:33         1   \n",
       "124002          1         2              1  2016-04-02 02:25:31         1   \n",
       "124004          1         1              1  2016-04-26 05:42:03         1   \n",
       "124008          1         2              1  2016-04-19 02:47:33         0   \n",
       "124009          1         3              2  2016-04-20 05:34:00         1   \n",
       "\n",
       "        HardwoodFloors  CatsAllowed  DogsAllowed  Doorman  Dishwasher  ...  \\\n",
       "4                    1            1            1        0           1  ...   \n",
       "6                    1            0            0        1           1  ...   \n",
       "9                    1            0            0        1           1  ...   \n",
       "10                   0            0            0        0           0  ...   \n",
       "15                   0            0            0        1           0  ...   \n",
       "...                ...          ...          ...      ...         ...  ...   \n",
       "124000               1            0            0        0           1  ...   \n",
       "124002               0            1            1        1           0  ...   \n",
       "124004               1            1            1        0           1  ...   \n",
       "124008               0            0            0        0           1  ...   \n",
       "124009               1            0            0        0           1  ...   \n",
       "\n",
       "        LaundryinUnit  RoofDeck  OutdoorSpace  DiningRoom  HighSpeedInternet  \\\n",
       "4                   0         0             0           1                  0   \n",
       "6                   0         0             0           0                  0   \n",
       "9                   1         0             0           0                  0   \n",
       "10                  0         0             0           0                  0   \n",
       "15                  0         0             0           0                  0   \n",
       "...               ...       ...           ...         ...                ...   \n",
       "124000              0         0             0           0                  0   \n",
       "124002              0         0             0           0                  0   \n",
       "124004              1         0             0           1                  0   \n",
       "124008              1         0             1           0                  0   \n",
       "124009              0         0             0           1                  0   \n",
       "\n",
       "        Balcony  SwimmingPool  LaundryInBuilding  NewConstruction  Terrace  \n",
       "4             0             0                  0                0        0  \n",
       "6             0             0                  0                0        0  \n",
       "9             0             0                  0                0        0  \n",
       "10            0             0                  0                0        0  \n",
       "15            0             0                  0                0        0  \n",
       "...         ...           ...                ...              ...      ...  \n",
       "124000        0             0                  0                0        0  \n",
       "124002        0             0                  1                0        0  \n",
       "124004        0             0                  0                0        0  \n",
       "124008        0             0                  0                0        0  \n",
       "124009        0             0                  0                0        0  \n",
       "\n",
       "[48343 rows x 24 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/train.json\")\n",
    "\n",
    "percentile_1 = df[\"price\"].quantile(0.01)\n",
    "percentile_9 = df[\"price\"].quantile(0.99)\n",
    "train_df = df[(df[\"price\"] > percentile_1) & (df[\"price\"] < percentile_9)].copy()\n",
    "train_df.loc[:,\"interest_level\"] = train_df[\"interest_level\"].replace({\"low\": 0,\"medium\": 1, \"high\": 2}).copy()\n",
    "train_df[\"features\"] = train_df[\"features\"].astype(str)\n",
    "train_df[\"features\"] = train_df[\"features\"].str.replace(r'[$$\\'\"\\s\\[\\]]', '', regex=True)\n",
    "list_features_train = []\n",
    "for index, row in train_df.iterrows():\n",
    "  for feature in row[\"features\"].split(\",\"):\n",
    "    list_features_train.append(feature)\n",
    "\n",
    "counter = Counter(list_features_train)\n",
    "top_21 = counter.most_common(21)\n",
    "top_21 = [x for x in top_21 if x[0] != \"\"]\n",
    "\n",
    "for feature_name in top_21:\n",
    "    train_df[feature_name[0]] = train_df[\"features\"].apply(lambda x: 1 if feature_name[0] in x.split(\",\") else 0)\n",
    "\n",
    "feature_list = [\"bathrooms\", \"bedrooms\", \"interest_level\", \"created\"] + [x[0] for x in top_21]\n",
    "\n",
    "train_df[\"bathrooms\"] = train_df[\"bathrooms\"].astype(int)\n",
    "\n",
    "X = train_df[feature_list].copy()\n",
    "y = train_df[\"price\"].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba154d",
   "metadata": {},
   "source": [
    "## 3. Implement the next methods:\n",
    "   1. Split data into 2 parts randomly with parameter test_size (ratio from 0 to 1), return training and test samples.\n",
    "   2. Randomly split data into 3 parts with parameters validation_size and test_size, return train, validation and test samples.\n",
    "   3. Split data into 2 parts with parameter date_split, return train and test samples split by date_split param.\n",
    "   4. Split data into 3 parts with parameters validation_date and test_date, return train, validation and test samples split by input params.\n",
    "   5. Make split procedure determenistic. What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60cf9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_2(X, y, test_size=0.2):\n",
    "    np.random.seed(21)\n",
    "    n_samples = X.shape[0]\n",
    "    ind = np.random.permutation(n_samples)\n",
    "    test_count = int(test_size * n_samples)\n",
    "    train_ind = ind[test_count:]\n",
    "    test_ind = ind[:test_count]\n",
    "    return X.iloc[train_ind], X.iloc[test_ind], y.iloc[train_ind], y.iloc[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd2e9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_3(X, y, test_size=0.2, validation_size=0.2):\n",
    "    np.random.seed(21)\n",
    "    n_samples = X.shape[0]\n",
    "    ind = np.random.permutation(n_samples)\n",
    "    validation_count = int(validation_size * n_samples)\n",
    "    test_count = int(test_size * n_samples)\n",
    "    train_count = int(n_samples - validation_count - test_count)\n",
    "\n",
    "    train_ind = ind[:train_count]\n",
    "    validation_ind = ind[train_count:train_count + validation_count]\n",
    "    test_ind = ind[train_count + validation_count:]\n",
    "\n",
    "    return (X.iloc[train_ind], X.iloc[validation_ind], X.iloc[test_ind],\n",
    "            y.iloc[train_ind], y.iloc[validation_ind], y.iloc[test_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d016e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_2_date(X, y, date_split=\"2016-06-16\"):\n",
    "    X[\"created\"] = pd.to_datetime(X[\"created\"])\n",
    "    train_ind = X.index[X[\"created\"] <= date_split]\n",
    "    test_ind = X.index[X[\"created\"] > date_split]\n",
    "    return X.loc[train_ind], X.loc[test_ind], y.loc[train_ind], y.loc[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5eab8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_3_date(X, y, date_split=\"2016-06-16\"):\n",
    "    X[\"created\"] = pd.to_datetime(X[\"created\"])\n",
    "    train_ind = X.index[X[\"created\"] < date_split]\n",
    "    validation_ind = X.index[X[\"created\"] == date_split]\n",
    "    test_ind = X.index[X[\"created\"] > date_split]\n",
    "    return (X.iloc[train_ind], X.iloc[validation_ind], X.iloc[test_ind],\n",
    "            y.iloc[train_ind], y.iloc[validation_ind], y.iloc[test_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577dec3",
   "metadata": {},
   "source": [
    "## 4. Implement the next cross-validation methods:\n",
    "   1. K-Fold, where k is the input parameter, returns a list of train and test indices. \n",
    "   2. Grouped K-Fold, where k and group_field are input parameters, returns list of train and test indices. \n",
    "   3. Stratified K-fold, where k and stratify_field are input parameters, returns list of train and test indices.\n",
    "   4. Time series split, where k and date_field are input parameters, returns list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aeb569f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold (X, k):\n",
    "    folds = []\n",
    "    all_ind = np.arange(X.shape[0])\n",
    "    start = 0\n",
    "    if k < X.shape[0]:\n",
    "        for i in range (k):\n",
    "            size = X.shape[0] // k\n",
    "            if i < X.shape[0] % k:\n",
    "                size += 1\n",
    "\n",
    "            end = start + size\n",
    "            full = all_ind[start:end]\n",
    "            test = full\n",
    "\n",
    "            train = np.setdiff1d(all_ind, full)\n",
    "            folds.append((train, test))\n",
    "            start = end\n",
    "\n",
    "        return folds\n",
    "\n",
    "    else:\n",
    "        print(f\"Number of splits cannot exceed the number of samples\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c93a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupKfold (X, k, group_field):\n",
    "    uniq = np.unique(group_field)\n",
    "    if k <= len(uniq):\n",
    "        for i in range (k):\n",
    "            full = uniq[i * len(uniq) // k : (i + 1) * len(uniq) // k]\n",
    "            test = (np.where(np.isin(group_field, full))[0])\n",
    "            train = (np.setdiff1d(np.arange(len(X)), test))\n",
    "            yield train, test\n",
    "    else:\n",
    "        print(f\"Number of splits cannot exceed the number of samples\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfb4057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratifyKfold (X, k, stratify_field):\n",
    "    uniq = np.unique(stratify_field)\n",
    "    folds = []\n",
    "\n",
    "    fold_sizes_per_class = {}\n",
    "    class_indices_dict = {}\n",
    "    for u in uniq:\n",
    "        ind = np.where(stratify_field == u)[0]\n",
    "        class_indices_dict[u] = ind\n",
    "\n",
    "        fold_size = []\n",
    "        for _ in range (k):\n",
    "            fold_size.append(len(ind) // k)\n",
    "        for i in range (len(ind) % k):\n",
    "            fold_size[i] += 1\n",
    "\n",
    "        fold_sizes_per_class[u] = fold_size\n",
    "\n",
    "    for i in range (k):\n",
    "        test_folds = []\n",
    "        train_folds = []\n",
    "        for u in uniq:\n",
    "            sizes = fold_sizes_per_class[u]\n",
    "            class_full = class_indices_dict[u]\n",
    "            start = sum(sizes[:i])\n",
    "            end = start + sizes[i]\n",
    "            train_folds.extend(class_full[:start])\n",
    "            train_folds.extend(class_full[end:])\n",
    "            test_folds.extend(class_full[start:end])\n",
    "\n",
    "        folds.append((np.sort(train_folds), np.sort(test_folds)))\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23a7694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSeriesSplit(k, date_field):\n",
    "    n_samples = len(date_field)\n",
    "    folds = []\n",
    "    test_size = n_samples//(k + 1)\n",
    "    for i in range(1, k + 1):\n",
    "        train_size = i * n_samples // (k + 1) + n_samples % (k + 1)\n",
    "        train = np.arange(train_size)\n",
    "        test = np.arange(train_size, train_size + test_size)\n",
    "        folds.append((train, test))\n",
    "    return(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae50fe",
   "metadata": {},
   "source": [
    "## 5. Cross-validation comparison\n",
    "   1. Apply all the validation methods implemented above to our dataset. To apply Stratified algorithm you should preprocess target.\n",
    "   2. Apply the appropriate methods from sklearn.\n",
    "   3. Compare the resulting feature distributions for the training part of the dataset between sklearn and your implementation.\n",
    "   4. Compare all validation schemes. Choose the best one. Explain your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "644cc196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38675, 24), (9668, 24), (38675,), (9668,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my train_test_split\n",
    "X_train, X_test, y_train, y_test = split_into_2(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1105084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38674, 24), (9669, 24), (38674,), (9669,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#org train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c901cd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29007, 24), (9668, 24), (9668, 24), (29007,), (9668,), (9668,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, x_validation, y_validation, y_train, y_test = split_into_3(\n",
    "    X, y, test_size=0.2, validation_size=0.2\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, x_validation.shape, y_validation.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e36f73bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40696, 24), (7647, 24), (40696,), (7647,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_into_2_date(\n",
    "    X, y, date_split=\"2016-06-16\"\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a484be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29007, 24), (9668, 24), (9668, 24), (29007,), (9668,), (9668,))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, x_validation, y_validation, y_train, y_test = split_into_3(\n",
    "    X, y, test_size=0.2, validation_size=0.2\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, x_validation.shape, y_validation.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "71285af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[24172 24173 24174 ... 48340 48341 48342]\n",
      "  Train: index length = 24171\n",
      "  Test:  index=[    0     1     2 ... 24169 24170 24171]\n",
      "  Test:  index length = 24172\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 24169 24170 24171]\n",
      "  Train: index length = 24172\n",
      "  Test:  index=[24172 24173 24174 ... 48340 48341 48342]\n",
      "  Test:  index length = 24171\n"
     ]
    }
   ],
   "source": [
    "#my KFold\n",
    "for i, (train_index, test_index) in enumerate(kfold(X=X, k=2)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Train: index length = {len(train_index)}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"  Test:  index length = {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f9aedc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[24172 24173 24174 ... 48340 48341 48342]\n",
      "  Train: index length = 24171\n",
      "  Test:  index=[    0     1     2 ... 24169 24170 24171]\n",
      "  Test:  index length = 24172\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 24169 24170 24171]\n",
      "  Train: index length = 24172\n",
      "  Test:  index=[24172 24173 24174 ... 48340 48341 48342]\n",
      "  Test:  index length = 24171\n"
     ]
    }
   ],
   "source": [
    "#org KFold\n",
    "kf = KFold(n_splits=2)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X=X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Train: index length = {len(train_index)}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"  Test:  index length = {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6cc3c39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     2     3 ... 48340 48341 48342]\n",
      "  Train: index length = 14671\n",
      "  Test:  index=[    1     4     5 ... 48336 48337 48338]\n",
      "  Test:  index length = 33672\n",
      "Fold 1:\n",
      "  Train: index=[    1     4     5 ... 48336 48337 48338]\n",
      "  Train: index length = 33672\n",
      "  Test:  index=[    0     2     3 ... 48340 48341 48342]\n",
      "  Test:  index length = 14671\n"
     ]
    }
   ],
   "source": [
    "#my GroupKFold\n",
    "for i, (train_index, test_index) in enumerate(groupKfold(X=X, k=2, group_field=X[\"interest_level\"])):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Train: index length = {len(train_index)}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"  Test:  index length = {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e42f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     2     3 ... 48340 48341 48342]\n",
      "  Train: index length = 14671\n",
      "  Test:  index=[    1     4     5 ... 48336 48337 48338]\n",
      "  Test:  index length = 33672\n",
      "Fold 1:\n",
      "  Train: index=[    1     4     5 ... 48336 48337 48338]\n",
      "  Train: index length = 33672\n",
      "  Test:  index=[    0     2     3 ... 48340 48341 48342]\n",
      "  Test:  index length = 14671\n"
     ]
    }
   ],
   "source": [
    "#org GroupKFold\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X=X, groups=X[\"interest_level\"])):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Train: index length = {len(train_index)}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"  Test:  index length = {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "76727f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess target\n",
    "mean_price = y.mean()\n",
    "\n",
    "def price_to_class(price):\n",
    "    if price < mean_price - 100:\n",
    "        return 3\n",
    "    elif mean_price - 100 <= price <= mean_price + 100:\n",
    "        return 4\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "y_preprocess = pd.DataFrame()\n",
    "y_preprocess[\"price\"] = y\n",
    "y_preprocess[\"class\"] = y_preprocess[\"price\"].apply(price_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a688be15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0:\n",
      "  Train: index=[23884 23885 23889 ... 48340 48341 48342]\n",
      "  Train: index length = 24171\n",
      "  Test:  index=[    0     1     2 ... 24370 24372 24380]\n",
      "  Test:  index length = 24172\n",
      "\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 24370 24372 24380]\n",
      "  Train: index length = 24172\n",
      "  Test:  index=[23884 23885 23889 ... 48340 48341 48342]\n",
      "  Test:  index length = 24171\n"
     ]
    }
   ],
   "source": [
    "#my StratifiedKFold\n",
    "for i, (train_index, test_index) in enumerate(stratifyKfold(X=X, k=2, stratify_field=y_preprocess[\"class\"])):\n",
    "    print()\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Train: index length = {len(train_index)}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"  Test:  index length = {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f90f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[23884 23885 23889 ... 48340 48341 48342]\n",
      "  Train: index length = 24171\n",
      "  Test:  index=[    0     1     2 ... 24370 24372 24380]\n",
      "  Test:  index length = 24172\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 24370 24372 24380]\n",
      "  Train: index length = 24172\n",
      "  Test:  index=[23884 23885 23889 ... 48340 48341 48342]\n",
      "  Test:  index length = 24171\n"
     ]
    }
   ],
   "source": [
    "#org StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X=X, y=y_preprocess[\"class\"])):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Train: index length = {len(train_index)}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"  Test:  index length = {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "caf7af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 16112 16113 16114]\n",
      "  Train: index length = 16115\n",
      "  Test:  index=[16115 16116 16117 ... 32226 32227 32228]\n",
      "  Test:  index length = 16114\n",
      "\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 32226 32227 32228]\n",
      "  Train: index length = 32229\n",
      "  Test:  index=[32229 32230 32231 ... 48340 48341 48342]\n",
      "  Test:  index length = 16114\n"
     ]
    }
   ],
   "source": [
    "#my TimeSeriesSplit\n",
    "for i, (train_index, test_index) in enumerate(timeSeriesSplit(k=2, date_field=X)):\n",
    "    print()\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Train: index length = {len(train_index)}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"  Test:  index length = {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4d00e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 16112 16113 16114]\n",
      "  Train: index length = 16115\n",
      "  Test:  index=[16115 16116 16117 ... 32226 32227 32228]\n",
      "  Test:  index length = 16114\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 32226 32227 32228]\n",
      "  Train: index length = 32229\n",
      "  Test:  index=[32229 32230 32231 ... 48340 48341 48342]\n",
      "  Test:  index length = 16114\n"
     ]
    }
   ],
   "source": [
    "#org TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=2)\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Train: index length = {len(train_index)}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    print(f\"  Test:  index length = {len(test_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5883501",
   "metadata": {},
   "source": [
    "Каждый метод кросс-валидации предназначен для разных задач и типов данных, поэтому их напрямую сравнивать и выбирать «лучший» в общем смысле не совсем корректно:\n",
    "\n",
    "* K-Fold — универсальный метод для равномерного разбиения данных без учета особенностей. Подходит для большинства задач с независимыми и одинаково распределёнными данными.\n",
    "\n",
    "* Grouped K-Fold — важен, когда данные сгруппированы (например, по клиентам или сессиям), чтобы группы не пересекались между train и test. Предотвращает утечку информации и обеспечивает более честную оценку.\n",
    "\n",
    "* Stratified K-Fold — необходим для задач с несбалансированными классами (например, классификация с редкими событиями), где нужно сохранить пропорции классов в каждом fold. Помогает улучшить обобщающую способность моделей.\n",
    "\n",
    "* Time Series Split — применяется при работе с временными рядами, где сохранение хронологического порядка критично, чтобы избежать утечки из будущего в прошлое и моделировать реальные сценарии прогнозирования.\n",
    "\n",
    "В связи с разными предпосылками и требованиями к данным, каждый метод эффективен в своем контексте, поэтому их нельзя сравнивать напрямую или выделять один универсальный лучший. Выбор зависит от задачи, структуры и природы данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0351ef",
   "metadata": {},
   "source": [
    "## 6. Feature Selection\n",
    "   1. Fit a Lasso regression model with normalized features. Use your method for splitting samples into 3 parts by field created with 60/20/20 ratio — train/validation/test.\n",
    "   2. Sort features by weight coefficients from model, fit model to top 10 features and compare quality.\n",
    "   3. Implement method for simple feature selection by nan-ratio in feature and correlation. Apply this method to feature set and take top 10 features, refit model and measure quality.\n",
    "   4. Implement permutation importance method and take top 10 features, refit model and measure quality.\n",
    "   5. Import Shap and also refit model on top 10 features.\n",
    "   6. Compare the quality of these methods for different aspects — speed, metrics and stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09e3f039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29007, 23), (9668, 23), (9668, 23), (29007,), (9668,), (9668,))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(\"created\", axis=1, errors=\"ignore\")\n",
    "\n",
    "X_train, X_test, X_validation, y_train, y_test, y_validation = split_into_3(\n",
    "    X, y, test_size=0.2, validation_size=0.2\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, X_validation.shape, y_train.shape, y_test.shape, y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "577de16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mrr(y_train, y_test, y_validation, train_predict, validation_predict, test_predict):\n",
    "    mae_train = mean_absolute_error(y_train, train_predict)\n",
    "    mae_val = mean_absolute_error(y_validation, validation_predict)\n",
    "    mae_test = mean_absolute_error(y_test, test_predict)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, train_predict))\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_validation, validation_predict))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, test_predict))\n",
    "    r2_train = r2_score(y_train, train_predict)\n",
    "    r2_val = r2_score(y_validation, validation_predict)\n",
    "    r2_test = r2_score(y_test, test_predict)\n",
    "\n",
    "    print(f\"MAE train: {mae_train}\")\n",
    "    print(f\"MAE val: {mae_val}\")\n",
    "    print(f\"MAE test: {mae_test}\")\n",
    "\n",
    "    print(f\"RMSE train: {rmse_train}\")\n",
    "    print(f\"RMSE val: {rmse_val}\")\n",
    "    print(f\"RMSE test: {rmse_test}\")\n",
    "\n",
    "    print(f\"R2 train: {r2_train}\")\n",
    "    print(f\"R2 val: {r2_val}\")\n",
    "    print(f\"R2 test: {r2_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dda28958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 724.4739538315874\n",
      "MAE val: 741.9960564379298\n",
      "MAE test: 726.191524951736\n",
      "RMSE train: 1044.2644748424946\n",
      "RMSE val: 1073.5651954487369\n",
      "RMSE test: 1067.3741796097713\n",
      "R2 train: 0.561775907984769\n",
      "R2 val: 0.564448828909797\n",
      "R2 test: 0.5366932502507034\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1, positive=True)\n",
    "lasso.fit(X_train, y_train)\n",
    "train_predict = lasso.predict(X_train)\n",
    "test_predict = lasso.predict(X_test)\n",
    "validation_predict = lasso.predict(X_validation)\n",
    "\n",
    "print_mrr(y_train, y_test, y_validation, train_predict, validation_predict, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f3040a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bathrooms: 1591.1045826966963\n",
      "Doorman: 583.7192878249056\n",
      "bedrooms: 449.1355869810811\n",
      "LaundryinUnit: 369.3364169492312\n",
      "DogsAllowed: 106.75249233311753\n",
      "Elevator: 94.15600922023562\n",
      "Terrace: 88.75450759542758\n",
      "FitnessCenter: 76.0343780165375\n",
      "DiningRoom: 41.359548844463376\n",
      "interest_level: 0.0\n",
      "HardwoodFloors: 0.0\n",
      "CatsAllowed: 0.0\n",
      "Dishwasher: 0.0\n",
      "NoFee: 0.0\n",
      "LaundryinBuilding: 0.0\n",
      "Pre-War: 0.0\n",
      "RoofDeck: 0.0\n",
      "OutdoorSpace: 0.0\n",
      "HighSpeedInternet: 0.0\n",
      "Balcony: 0.0\n",
      "SwimmingPool: 0.0\n",
      "LaundryInBuilding: 0.0\n",
      "NewConstruction: 0.0\n"
     ]
    }
   ],
   "source": [
    "if \"created\" in feature_list:\n",
    "    feature_list.remove(\"created\")\n",
    "coefficients = lasso.coef_\n",
    "ind = dict(zip(feature_list, coefficients))\n",
    "ind_sorted = sorted(ind.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "for feature, weight in ind_sorted:\n",
    "    print(f\"{feature}: {weight}\")\n",
    "\n",
    "keys_list = list(ind.keys())\n",
    "top_10 = keys_list[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ddc3b1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 724.4739538315874\n",
      "MAE val: 711.9057674496846\n",
      "MAE test: 701.4517149591959\n",
      "RMSE train: 1044.2644748424946\n",
      "RMSE val: 1038.2380269017747\n",
      "RMSE test: 1032.9891080769148\n",
      "R2 train: 0.561775907984769\n",
      "R2 val: 0.5926420448390284\n",
      "R2 test: 0.5660629558097283\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train[top_10], y_train)\n",
    "test_predict = lasso.predict(X_test[top_10])\n",
    "validation_predict = lasso.predict(X_validation[top_10])\n",
    "\n",
    "print_mrr(y_train, y_test, y_validation, train_predict, validation_predict, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cd1d0c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathrooms            False\n",
       "bedrooms             False\n",
       "interest_level       False\n",
       "Elevator             False\n",
       "HardwoodFloors       False\n",
       "CatsAllowed          False\n",
       "DogsAllowed          False\n",
       "Doorman              False\n",
       "Dishwasher           False\n",
       "NoFee                False\n",
       "LaundryinBuilding    False\n",
       "FitnessCenter        False\n",
       "Pre-War              False\n",
       "LaundryinUnit        False\n",
       "RoofDeck             False\n",
       "OutdoorSpace         False\n",
       "DiningRoom           False\n",
       "HighSpeedInternet    False\n",
       "Balcony              False\n",
       "SwimmingPool         False\n",
       "LaundryInBuilding    False\n",
       "NewConstruction      False\n",
       "Terrace              False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79012522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nan = X.copy()\n",
    "n_rows, n_cols = X_nan.shape\n",
    "nan_ratio = 0.1\n",
    "nan_count = int(n_rows * n_cols * nan_ratio)\n",
    "mask = np.array([True]*nan_count + [False]*(n_rows * n_cols - nan_count))\n",
    "np.random.shuffle(mask)\n",
    "np.random.seed(21)\n",
    "mask = mask.reshape(n_rows, n_cols)\n",
    "X_nan = X_nan.mask(mask)\n",
    "\n",
    "feature_list_nan = feature_list.copy()\n",
    "feature_list_nan.append(\"Nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0faf4959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>Elevator</th>\n",
       "      <th>HardwoodFloors</th>\n",
       "      <th>CatsAllowed</th>\n",
       "      <th>DogsAllowed</th>\n",
       "      <th>Doorman</th>\n",
       "      <th>Dishwasher</th>\n",
       "      <th>NoFee</th>\n",
       "      <th>...</th>\n",
       "      <th>LaundryinUnit</th>\n",
       "      <th>RoofDeck</th>\n",
       "      <th>OutdoorSpace</th>\n",
       "      <th>DiningRoom</th>\n",
       "      <th>HighSpeedInternet</th>\n",
       "      <th>Balcony</th>\n",
       "      <th>SwimmingPool</th>\n",
       "      <th>LaundryInBuilding</th>\n",
       "      <th>NewConstruction</th>\n",
       "      <th>Terrace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124002</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124009</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48343 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms interest_level  Elevator  HardwoodFloors  \\\n",
       "4             1.0       1.0              1       0.0             1.0   \n",
       "6             1.0       2.0              0       1.0             1.0   \n",
       "9             1.0       2.0              1       1.0             1.0   \n",
       "10            1.0       3.0              1       NaN             0.0   \n",
       "15            1.0       0.0              0       1.0             0.0   \n",
       "...           ...       ...            ...       ...             ...   \n",
       "124000        1.0       3.0            NaN       1.0             1.0   \n",
       "124002        1.0       2.0              1       1.0             0.0   \n",
       "124004        1.0       1.0              1       1.0             1.0   \n",
       "124008        1.0       2.0              1       0.0             0.0   \n",
       "124009        1.0       3.0              2       1.0             1.0   \n",
       "\n",
       "        CatsAllowed  DogsAllowed  Doorman  Dishwasher  NoFee  ...  \\\n",
       "4               1.0          NaN      0.0         1.0    0.0  ...   \n",
       "6               0.0          0.0      1.0         1.0    1.0  ...   \n",
       "9               0.0          0.0      1.0         1.0    0.0  ...   \n",
       "10              0.0          0.0      0.0         0.0    0.0  ...   \n",
       "15              0.0          0.0      NaN         0.0    0.0  ...   \n",
       "...             ...          ...      ...         ...    ...  ...   \n",
       "124000          0.0          0.0      0.0         1.0    0.0  ...   \n",
       "124002          1.0          1.0      1.0         0.0    NaN  ...   \n",
       "124004          1.0          1.0      0.0         1.0    1.0  ...   \n",
       "124008          0.0          0.0      0.0         1.0    1.0  ...   \n",
       "124009          NaN          0.0      0.0         1.0    1.0  ...   \n",
       "\n",
       "        LaundryinUnit  RoofDeck  OutdoorSpace  DiningRoom  HighSpeedInternet  \\\n",
       "4                 0.0       0.0           0.0         1.0                0.0   \n",
       "6                 0.0       0.0           0.0         0.0                0.0   \n",
       "9                 1.0       0.0           0.0         0.0                0.0   \n",
       "10                0.0       0.0           0.0         0.0                0.0   \n",
       "15                0.0       0.0           0.0         0.0                NaN   \n",
       "...               ...       ...           ...         ...                ...   \n",
       "124000            NaN       0.0           0.0         0.0                0.0   \n",
       "124002            0.0       0.0           0.0         0.0                0.0   \n",
       "124004            1.0       0.0           0.0         1.0                0.0   \n",
       "124008            1.0       0.0           1.0         0.0                0.0   \n",
       "124009            NaN       NaN           0.0         1.0                0.0   \n",
       "\n",
       "        Balcony  SwimmingPool  LaundryInBuilding  NewConstruction  Terrace  \n",
       "4           0.0           0.0                NaN              0.0      NaN  \n",
       "6           0.0           0.0                0.0              0.0      0.0  \n",
       "9           NaN           0.0                0.0              0.0      0.0  \n",
       "10          0.0           0.0                0.0              0.0      0.0  \n",
       "15          0.0           0.0                0.0              0.0      NaN  \n",
       "...         ...           ...                ...              ...      ...  \n",
       "124000      0.0           NaN                0.0              0.0      0.0  \n",
       "124002      0.0           0.0                NaN              NaN      0.0  \n",
       "124004      0.0           0.0                0.0              0.0      0.0  \n",
       "124008      0.0           0.0                0.0              NaN      0.0  \n",
       "124009      0.0           0.0                0.0              0.0      0.0  \n",
       "\n",
       "[48343 rows x 23 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e6073cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = dict(X_nan.isna().sum())\n",
    "nan_counts_sorted = sorted(nan_counts.items(), key=lambda x: x[1])\n",
    "keys_list_nan = list(dict(nan_counts_sorted).keys())\n",
    "top_10_nan = keys_list_nan[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4faa387a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2576, 23), (858, 23), (858, 23), (2576,), (858,), (858,))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nan = X_nan.dropna()\n",
    "X_train, X_test, X_validation, y_train, y_test, y_validation = split_into_3(\n",
    "    X_nan, y, test_size=0.2, validation_size=0.2\n",
    ")\n",
    "X_train.shape, X_test.shape, X_validation.shape, y_train.shape, y_test.shape, y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce2c7d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 1088.5051116979018\n",
      "MAE val: 1180.5501837478423\n",
      "MAE test: 1138.1483511425922\n",
      "RMSE train: 1488.2618888201878\n",
      "RMSE val: 1631.2716023359403\n",
      "RMSE test: 1602.341012205051\n",
      "R2 train: 0.005347275141870278\n",
      "R2 val: -0.017594721772081767\n",
      "R2 test: -0.014981493706352822\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train[top_10_nan], y_train)\n",
    "train_predict = lasso.predict(X_train[top_10_nan])\n",
    "test_predict = lasso.predict(X_test[top_10_nan])\n",
    "validation_predict = lasso.predict(X_validation[top_10_nan])\n",
    "\n",
    "print_mrr(y_train, y_test, y_validation, train_predict, validation_predict, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e123bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle = X.copy()\n",
    "for feature in top_10:\n",
    "    X_shuffle[feature] = np.random.permutation(X_shuffle[feature].values)\n",
    "\n",
    "X_train, X_test, X_validation, y_train, y_test, y_validation = split_into_3(\n",
    "    X_shuffle, y, test_size=0.2, validation_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6aa5ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 1043.2324649712862\n",
      "MAE val: 1077.3973486765317\n",
      "MAE test: 1047.625455229421\n",
      "RMSE train: 1466.0290904859091\n",
      "RMSE val: 1510.8894134879615\n",
      "RMSE test: 1472.1494882480397\n",
      "R2 train: 0.13630497426179056\n",
      "R2 val: 0.13732404089351868\n",
      "R2 test: 0.11866895908309427\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "train_predict = lasso.predict(X_train)\n",
    "test_predict = lasso.predict(X_test)\n",
    "validation_predict = lasso.predict(X_validation)\n",
    "\n",
    "print_mrr(y_train, y_test, y_validation, train_predict, validation_predict, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "048bf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_validation, y_train, y_test, y_validation = split_into_3(\n",
    "    X, y, test_size=0.2, validation_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5a242626",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "train_predict = lasso.predict(X_train)\n",
    "test_predict = lasso.predict(X_test)\n",
    "validation_predict = lasso.predict(X_validation)\n",
    "\n",
    "exp = shap.Explainer(lasso, X_train)\n",
    "shap_values = exp(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73a8cd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bathrooms: 520.7289139593444\n",
      "bedrooms: 447.9793352461869\n",
      "interest_level: 220.7924431091073\n",
      "Elevator: 104.77977605515683\n",
      "HardwoodFloors: 60.18294556314592\n",
      "CatsAllowed: 36.73324135553417\n",
      "DogsAllowed: 64.59116569913535\n",
      "Doorman: 272.47851963511715\n",
      "Dishwasher: 73.06092165032292\n",
      "NoFee: 40.01597182008555\n",
      "LaundryinBuilding: 85.33191978834125\n",
      "FitnessCenter: 84.05070349710664\n",
      "Pre-War: 28.096890196014844\n",
      "LaundryinUnit: 123.6462958109627\n",
      "RoofDeck: 26.040386128471248\n",
      "OutdoorSpace: 13.138869034877443\n",
      "DiningRoom: 33.34142171949512\n",
      "HighSpeedInternet: 35.50786999364339\n",
      "Balcony: 4.397101046180796\n",
      "SwimmingPool: 9.15944722096128\n",
      "LaundryInBuilding: 25.90026203426125\n",
      "NewConstruction: 15.646253877050455\n",
      "Terrace: 16.141918494937084\n"
     ]
    }
   ],
   "source": [
    "mean_abs_shap = np.mean(np.abs(shap_values.values), axis=0)\n",
    "shap_val = {}\n",
    "for i, feature_name in enumerate(feature_list):\n",
    "    print(f\"{feature_name}: {mean_abs_shap[i]}\")\n",
    "    shap_val[feature_name] = mean_abs_shap[i]\n",
    "\n",
    "shap_val_sorted = sorted(shap_val.items(), key=lambda x: x[1], reverse=True)\n",
    "keys_list = list(dict(shap_val_sorted).keys())\n",
    "top_10 = keys_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "53d9c8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 687.5224005449379\n",
      "MAE val: 702.924854343843\n",
      "MAE test: 692.8063641766822\n",
      "RMSE train: 994.1808495100179\n",
      "RMSE val: 1025.522533326079\n",
      "RMSE test: 1022.1104664980079\n",
      "R2 train: 0.6028029368872916\n",
      "R2 val: 0.6025589205526094\n",
      "R2 test: 0.5751546072948159\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train[top_10], y_train)\n",
    "test_predict = lasso.predict(X_test[top_10])\n",
    "validation_predict = lasso.predict(X_validation[top_10])\n",
    "\n",
    "print_mrr(y_train, y_test, y_validation, train_predict, validation_predict, test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1eaeb6",
   "metadata": {},
   "source": [
    "При сравнении методов отбора признаков — простой сортировки по коэффициентам Lasso и SHAP — результаты в целом оказались схожими и показали хорошее качество модели. Однако метод на основе пропущенных значений (nan-ratio) пострадал из-за наличия многих пропусков в данных, что привело к неполным и менее точным результатам. Метод permutation importance ухудшил корреляционные зависимости между признаками из-за случайного перемешивания, что отразилось на ошибках и устойчивости модели. В целом, SHAP и простая сортировка продемонстрировали хорошую стабильность и метрики по сравнению с другими подходами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab64eba",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter optimization\n",
    "   1. Implement grid search and random search methods for alpha and l1_ratio for sklearn's ElasticNet model.\n",
    "   2. Find the best combination of model hyperparameters.\n",
    "   3. Fit the resulting model.\n",
    "   4. Import optuna and configure the same experiment with ElasticNet.\n",
    "   5. Estimate metrics and compare approaches.\n",
    "   6. Run optuna on one of the cross-validation schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "13b6e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"alpha\" : [0.1, 0.5, 0.9, 0.01, 0.001, 1],\n",
    "    \"l1_ratio\" : [0.1, 0.5, 0.9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "38308739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'l1_ratio': 0.9}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic = ElasticNet()\n",
    "grid_search = GridSearchCV(estimator=elastic, param_grid=param, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "362ec69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1_ratio': 0.9, 'alpha': 0.01}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic = ElasticNet()\n",
    "random_search = RandomizedSearchCV(estimator=elastic, param_distributions=param, n_iter=21, cv=3)\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2160ad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 687.5224005449379\n",
      "MAE val: 699.143426049331\n",
      "MAE test: 688.4418245392203\n",
      "RMSE train: 994.1808495100179\n",
      "RMSE val: 1018.718116123141\n",
      "RMSE test: 1015.0598233476362\n",
      "R2 train: 0.6028029368872916\n",
      "R2 val: 0.6078155249351919\n",
      "R2 test: 0.5809956624903004\n"
     ]
    }
   ],
   "source": [
    "elastic = ElasticNet(alpha=0.01, l1_ratio=0.9)\n",
    "elastic.fit(X_train, y_train)\n",
    "test_predict = elastic.predict(X_test)\n",
    "validation_predict = elastic.predict(X_validation)\n",
    "\n",
    "print_mrr(y_train, y_test, y_validation, train_predict, validation_predict, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c994bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-26 13:44:15,096] A new study created in memory with name: no-name-99987fce-13c3-490e-86a4-08ffd41b2a63\n",
      "[I 2025-10-26 13:44:15,809] Trial 0 finished with value: 0.6001725420951419 and parameters: {'alpha': 0.02447962499188788, 'l1_ratio': 0.4468518759209197}. Best is trial 0 with value: 0.6001725420951419.\n",
      "[I 2025-10-26 13:44:16,119] Trial 1 finished with value: 0.5608271146449809 and parameters: {'alpha': 0.32056834594950123, 'l1_ratio': 0.558542537721281}. Best is trial 0 with value: 0.6001725420951419.\n",
      "[I 2025-10-26 13:44:17,996] Trial 2 finished with value: 0.6011191620556879 and parameters: {'alpha': 0.00019718947086787015, 'l1_ratio': 0.04783458262755269}. Best is trial 2 with value: 0.6011191620556879.\n",
      "[I 2025-10-26 13:44:19,364] Trial 3 finished with value: 0.6011304481922473 and parameters: {'alpha': 0.001460119485319444, 'l1_ratio': 0.41611906249831276}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:19,756] Trial 4 finished with value: 0.5874199484408261 and parameters: {'alpha': 0.08367019158322384, 'l1_ratio': 0.25713473359737593}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:21,155] Trial 5 finished with value: 0.6011264154386367 and parameters: {'alpha': 0.0010168346842029075, 'l1_ratio': 0.4525266028087708}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:22,239] Trial 6 finished with value: 0.6011220668966833 and parameters: {'alpha': 0.013886290433790178, 'l1_ratio': 0.9805981628840643}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:22,582] Trial 7 finished with value: 0.5787324739656797 and parameters: {'alpha': 0.1504636429331494, 'l1_ratio': 0.4137737113045331}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:23,198] Trial 8 finished with value: 0.5991437151932757 and parameters: {'alpha': 0.03336264088287734, 'l1_ratio': 0.4111908142514523}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:24,576] Trial 9 finished with value: 0.6010850182528521 and parameters: {'alpha': 0.004028594692188481, 'l1_ratio': 0.009006942609221635}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:26,259] Trial 10 finished with value: 0.6011153920515384 and parameters: {'alpha': 0.0001146672176321396, 'l1_ratio': 0.7140610001436246}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:27,647] Trial 11 finished with value: 0.6011253715758031 and parameters: {'alpha': 0.0013468164398397064, 'l1_ratio': 0.6340687339613522}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:29,237] Trial 12 finished with value: 0.601127589414687 and parameters: {'alpha': 0.0008900767789892324, 'l1_ratio': 0.28872738122195074}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:30,897] Trial 13 finished with value: 0.6011290062826651 and parameters: {'alpha': 0.0009410427374589613, 'l1_ratio': 0.2192505548845631}. Best is trial 3 with value: 0.6011304481922473.\n",
      "[I 2025-10-26 13:44:32,269] Trial 14 finished with value: 0.6011328680933304 and parameters: {'alpha': 0.00230063321857546, 'l1_ratio': 0.1910608105001324}. Best is trial 14 with value: 0.6011328680933304.\n",
      "[I 2025-10-26 13:44:33,865] Trial 15 finished with value: 0.6010892451951114 and parameters: {'alpha': 0.004607076697119116, 'l1_ratio': 0.1581762919778062}. Best is trial 14 with value: 0.6011328680933304.\n",
      "[I 2025-10-26 13:44:37,162] Trial 16 finished with value: 0.6011270300607915 and parameters: {'alpha': 0.0035331709241297037, 'l1_ratio': 0.8345739301613089}. Best is trial 14 with value: 0.6011328680933304.\n",
      "[I 2025-10-26 13:44:41,952] Trial 17 finished with value: 0.6011199528738723 and parameters: {'alpha': 0.0003254792290632261, 'l1_ratio': 0.3167943456505523}. Best is trial 14 with value: 0.6011328680933304.\n",
      "[I 2025-10-26 13:44:42,664] Trial 18 finished with value: 0.44214432704586054 and parameters: {'alpha': 0.7484671602593687, 'l1_ratio': 0.14173544469338156}. Best is trial 14 with value: 0.6011328680933304.\n",
      "[I 2025-10-26 13:44:46,833] Trial 19 finished with value: 0.6011184176126068 and parameters: {'alpha': 0.0004032555672121847, 'l1_ratio': 0.6160526266047057}. Best is trial 14 with value: 0.6011328680933304.\n",
      "[I 2025-10-26 13:44:49,588] Trial 20 finished with value: 0.600993382662287 and parameters: {'alpha': 0.008659567888250844, 'l1_ratio': 0.3301933958907146}. Best is trial 14 with value: 0.6011328680933304.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.00230063321857546, 'l1_ratio': 0.1910608105001324}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.0001, 1.0, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "    elastic = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    score = cross_val_score(elastic, X_train, y_train, cv=3, scoring=\"r2\")\n",
    "    return score.mean()\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=21)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00b41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train: 687.5224005449379\n",
      "MAE val: 699.0628583288054\n",
      "MAE test: 688.285092718828\n",
      "RMSE train: 994.1808495100179\n",
      "RMSE val: 1018.7968817411861\n",
      "RMSE test: 1014.9099982414439\n",
      "R2 train: 0.6028029368872916\n",
      "R2 val: 0.6077548764667204\n",
      "R2 test: 0.5811193453213579\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "elastic = ElasticNet(alpha=0.001845453427371508, l1_ratio=0.009067891349687607)\n",
    "elastic.fit(X_train, y_train)\n",
    "test_predict = elastic.predict(X_test)\n",
    "validation_predict = elastic.predict(X_validation)\n",
    "\n",
    "print_mrr(y_train, y_test, y_validation, train_predict, validation_predict, test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
